{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9bnTPRCwcuC"
   },
   "outputs": [],
   "source": [
    "# --- C√âLULA 1: INSTALA√á√ÉO SEGURA ---\n",
    "# Instala apenas o SDK do Gemini, sem quebrar o Colab\n",
    "!pip install -q -U google-generativeai\n",
    "print(\"‚úÖ Instala√ß√£o conclu√≠da. Pode rodar a pr√≥xima c√©lula.\")\n",
    "\n",
    "# --- C√âLULA 2: CONEX√ÉO (LIMPA) ---\n",
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "import sys\n",
    "\n",
    "# 1. Configura Chave\n",
    "try:\n",
    "    GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
    "except Exception:\n",
    "    GEMINI_API_KEY = None\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    GEMINI_API_KEY = input(\"Insira aqui sua chave\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# 2. Seleciona o modelo que sabemos que funcionou (2.5-flash)\n",
    "# O script anterior j√° nos confirmou que voc√™ tem acesso a ele.\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "print(f\"‚öôÔ∏è Configurando modelo: {MODEL_NAME}\")\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "try:\n",
    "    resp = model.generate_content(\"Responda apenas: Conectado\")\n",
    "    print(f\"‚úÖ Status: {resp.text.strip()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# --- C√âLULA 3: UPLOAD DE ARQUIVO LOCAL ---\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "print(\"üìÇ Clique no bot√£o abaixo para fazer upload do 'olist_products_dataset.csv'\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verifica se o upload funcionou\n",
    "if uploaded:\n",
    "    # Pega o nome do primeiro arquivo enviado\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    print(f\"\\n‚úÖ Arquivo recebido: {filename}\")\n",
    "\n",
    "    # L√™ o CSV direto da mem√≥ria\n",
    "    try:\n",
    "        df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
    "        print(f\"üìä Dataset carregado: {len(df)} linhas.\")\n",
    "\n",
    "        # --- PREPARA√á√ÉO DOS DADOS (ETL) ---\n",
    "        print(\"‚öôÔ∏è Preparando descri√ß√µes para o Gemini...\")\n",
    "\n",
    "        def criar_descricao(row):\n",
    "            partes = []\n",
    "            if pd.notna(row.get(\"product_category_name\")):\n",
    "                partes.append(f\"Categoria: {row['product_category_name']}\")\n",
    "            if pd.notna(row.get(\"product_weight_g\")):\n",
    "                partes.append(f\"Peso: {row['product_weight_g']}g\")\n",
    "\n",
    "            # Se n√£o tiver nada, retorna vazio\n",
    "            if not partes:\n",
    "                return \"\"\n",
    "            return \" | \".join(partes)\n",
    "\n",
    "        df[\"descricao_sintetica\"] = df.apply(criar_descricao, axis=1)\n",
    "\n",
    "        # Filtra produtos sem descri√ß√£o ou muito curtos\n",
    "        df_proc = df[df[\"descricao_sintetica\"].str.len() > 5].copy()\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        print(\n",
    "            f\"üöÄ Tudo pronto! {len(df_proc)} produtos qualificados para enriquecimento.\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o CSV: {e}\")\n",
    "        print(\"Verifique se o arquivo √© realmente um CSV separado por v√≠rgulas.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum arquivo foi enviado. Rode a c√©lula novamente.\")\n",
    "\n",
    "# C√©lula 4 ‚Äî Engenharia de Prompt e Descri√ß√£o Sint√©tica\n",
    "\n",
    "\n",
    "# 1. Prepara√ß√£o dos dados (Criando input para o LLM)\n",
    "def criar_descricao_sintetica(row):\n",
    "    partes = []\n",
    "    # Tratamento b√°sico de nulos e formata√ß√£o\n",
    "    if pd.notna(row.get(\"product_category_name\")):\n",
    "        partes.append(f\"Categoria Original: {row['product_category_name']}\")\n",
    "    if pd.notna(row.get(\"product_weight_g\")):\n",
    "        partes.append(f\"Peso: {row['product_weight_g']}g\")\n",
    "    if pd.notna(row.get(\"product_length_cm\")):\n",
    "        dims = f\"{row['product_length_cm']}x{row['product_width_cm']}x{row['product_height_cm']}\"\n",
    "        partes.append(f\"Dimens√µes (CxLxA): {dims} cm\")\n",
    "\n",
    "    return \" | \".join(partes)\n",
    "\n",
    "\n",
    "df[\"descricao_sintetica\"] = df.apply(criar_descricao_sintetica, axis=1)\n",
    "# Filtra apenas quem tem alguma informa√ß√£o\n",
    "df_proc = df[df[\"descricao_sintetica\"].str.len() > 10].copy()\n",
    "\n",
    "# 2. Defini√ß√£o do Prompt do Sistema\n",
    "# Dica de Data Engineer: Definir o schema esperado ajuda na valida√ß√£o posterior\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Voc√™ √© um especialista em categoriza√ß√£o de produtos e Master Data Management.\n",
    "Analise os dados t√©cnicos do produto e enrique√ßa as informa√ß√µes.\n",
    "\n",
    "REGRAS DE SA√çDA:\n",
    "1. Retorne APENAS um objeto JSON v√°lido.\n",
    "2. N√£o use blocos de c√≥digo Markdown (```json).\n",
    "3. Se n√£o conseguir identificar, use null.\n",
    "\n",
    "SCHEMA JSON ESPERADO:\n",
    "{\n",
    "  \"categoria_normalizada\": \"string (ex: Eletr√¥nicos, Casa e Decora√ß√£o)\",\n",
    "  \"subcategoria\": \"string\",\n",
    "  \"tags\": [\"string\", \"string\"],\n",
    "  \"perfil_logistico\": \"string (ex: Leve, Pesado, Sobredimensionado)\",\n",
    "  \"publico_alvo\": \"string\",\n",
    "  \"sugestao_nome_produto\": \"string (um nome comercial atrativo baseado nos dados)\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Dados preparados. Linhas para processamento: {len(df_proc)}\")\n",
    "\n",
    "# --- C√âLULA 5: FUN√á√ÉO DE EXTRA√á√ÉO ROBUSTA (ANTI-429) ---\n",
    "import time\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "def limpar_json(text):\n",
    "    \"\"\"Remove caracteres indesejados do Markdown.\"\"\"\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```json\"):\n",
    "        text = text[7:]\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text[3:]\n",
    "    if text.endswith(\"```\"):\n",
    "        text = text[:-3]\n",
    "    return text\n",
    "\n",
    "\n",
    "def extrair_features(descricao, tentativas_max=3):\n",
    "    prompt = f\"DADOS DO PRODUTO:\\n{descricao}\\n\\nRetorne o JSON.\"\n",
    "\n",
    "    # SYSTEM PROMPT (Recapitulando para garantir o contexto na fun√ß√£o)\n",
    "    sys_prompt = \"\"\"\n",
    "    Voc√™ √© um especialista em e-commerce. Retorne APENAS um JSON v√°lido.\n",
    "    Campos: categoria_normalizada, subcategoria, tags (lista), perfil_logistico, publico_alvo, sugestao_nome_produto.\n",
    "    Use null se n√£o souber.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(tentativas_max):\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                [sys_prompt, prompt],\n",
    "                generation_config={\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"response_mime_type\": \"application/json\",\n",
    "                },\n",
    "            )\n",
    "            return json.loads(limpar_json(response.text))\n",
    "\n",
    "        except Exception as e:\n",
    "            erro_str = str(e)\n",
    "\n",
    "            # Se o erro for de COTA (429), precisamos esperar mais tempo\n",
    "            if \"429\" in erro_str or \"quota\" in erro_str.lower():\n",
    "                wait_time = 30  # Espera 30 segundos (Tier gratuito √© restrito)\n",
    "                print(\n",
    "                    f\"‚è≥ Cota atingida. Esperando {wait_time}s para tentar novamente...\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # Outros erros (ex: JSON inv√°lido), espera pouco\n",
    "                print(f\"‚ö†Ô∏è Erro na tentativa {i + 1}: {e}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "    return None  # Desiste ap√≥s as tentativas\n",
    "\n",
    "\n",
    "# --- C√âLULA 6: PROCESSAMENTO SEGURO (ANTI-429) ---\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Limite pequeno para garantir sucesso no teste\n",
    "SAMPLE_SIZE = 10\n",
    "df_sample = df_proc.sample(n=min(SAMPLE_SIZE, len(df_proc)), random_state=42)\n",
    "resultados = []\n",
    "\n",
    "print(f\"üöÄ Processando {len(df_sample)} itens com Gemini 2.5...\")\n",
    "\n",
    "\n",
    "def extrair_features_safe(texto):\n",
    "    prompt = f\"Analise: {texto}. Retorne JSON com campos: categoria_normalizada, tags, publico_alvo.\"\n",
    "    try:\n",
    "        # Tenta chamar a API\n",
    "        resp = model.generate_content(\n",
    "            prompt, generation_config={\"response_mime_type\": \"application/json\"}\n",
    "        )\n",
    "        return json.loads(resp.text)\n",
    "    except Exception as e:\n",
    "        # Se der erro (provavelmente cota), retorna None mas n√£o quebra o loop\n",
    "        return None\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "    dados = extrair_features_safe(row[\"descricao_sintetica\"])\n",
    "\n",
    "    if dados:\n",
    "        resultados.append({**row.to_dict(), **dados})\n",
    "\n",
    "    # PAUSA OBRIGAT√ìRIA PARA O GEMINI 2.5 (PLANO FREE)\n",
    "    # Ele permite poucas chamadas por minuto. 10s √© seguro.\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"\\n‚úÖ Sucesso! {len(resultados)} itens gerados.\")\n",
    "df_final = pd.DataFrame(resultados)\n",
    "display(df_final.head())\n",
    "\n",
    "# --- C√âLULA 7: EXPORTA√á√ÉO E DOWNLOAD ---\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "# Define nomes dos arquivos\n",
    "csv_filename = \"olist_enriched_sample.csv\"\n",
    "json_filename = \"olist_enriched_sample.json\"\n",
    "\n",
    "# Verifica qual dataframe est√° ativo (caso tenha rodado c√≥digos diferentes)\n",
    "if \"df_final\" in locals():\n",
    "    df_export = df_final\n",
    "elif \"df_enriquecido\" in locals():\n",
    "    df_export = df_enriquecido\n",
    "else:\n",
    "    # Fallback para o √∫ltimo df usado\n",
    "    df_export = pd.DataFrame(resultados)\n",
    "\n",
    "# Salva em CSV\n",
    "df_export.to_csv(csv_filename, index=False)\n",
    "print(f\"‚úÖ CSV salvo: {csv_filename}\")\n",
    "\n",
    "# Salva em JSON (Formato orientado a registros, bom para NoSQL/MongoDB)\n",
    "df_export.to_json(json_filename, orient=\"records\", indent=2, force_ascii=False)\n",
    "print(f\"‚úÖ JSON salvo: {json_filename}\")\n",
    "\n",
    "# Dispara o download no navegador\n",
    "print(\"\\n‚¨áÔ∏è Baixando arquivos para seu computador...\")\n",
    "files.download(csv_filename)\n",
    "files.download(json_filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}